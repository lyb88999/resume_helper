#!/bin/bash

# ç®€åŽ†ä¼˜åŒ–ç³»ç»Ÿå¼€å‘çŽ¯å¢ƒè®¾ç½®è„šæœ¬
set -e

echo "ðŸš€ å¼€å§‹è®¾ç½®ç®€åŽ†ä¼˜åŒ–ç³»ç»Ÿå¼€å‘çŽ¯å¢ƒ..."

# æ£€æŸ¥å¿…è¦å·¥å…·
check_prerequisites() {
    echo "ðŸ“‹ æ£€æŸ¥å‰ç½®æ¡ä»¶..."
    
    # æ£€æŸ¥Go
    if ! command -v go &> /dev/null; then
        echo "âŒ Goæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Go 1.21+"
        exit 1
    fi
    
    # æ£€æŸ¥Node.js
    if ! command -v node &> /dev/null; then
        echo "âŒ Node.jsæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Node.js 18+"
        exit 1
    fi
    
    # æ£€æŸ¥Docker
    if ! command -v docker &> /dev/null; then
        echo "âŒ Dockeræœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Docker"
        exit 1
    fi
    
    # æ£€æŸ¥Docker Compose
    if ! command -v docker-compose &> /dev/null; then
        echo "âŒ Docker Composeæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Docker Compose"
        exit 1
    fi
    
    echo "âœ… å‰ç½®æ¡ä»¶æ£€æŸ¥é€šè¿‡"
}

# åˆå§‹åŒ–åŽç«¯é¡¹ç›®
setup_backend() {
    echo "ðŸ”§ è®¾ç½®åŽç«¯é¡¹ç›®..."
    
    # åˆå§‹åŒ–Goæ¨¡å—
    echo "ðŸ“¦ åˆå§‹åŒ–Goæ¨¡å—..."
    go mod tidy
    
    # å®‰è£…wireä»£ç ç”Ÿæˆå·¥å…·
    echo "ðŸ› ï¸  å®‰è£…ä»£ç ç”Ÿæˆå·¥å…·..."
    go install github.com/google/wire/cmd/wire@latest
    go install google.golang.org/protobuf/cmd/protoc-gen-go@latest
    go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest
    
    # ç”Ÿæˆprotoæ–‡ä»¶
    echo "ðŸ“„ ç”Ÿæˆprotobufæ–‡ä»¶..."
    find backend/shared/proto -name "*.proto" -exec protoc \
        --go_out=. \
        --go_opt=paths=source_relative \
        --go-grpc_out=. \
        --go-grpc_opt=paths=source_relative \
        {} \;
    
    echo "âœ… åŽç«¯é¡¹ç›®è®¾ç½®å®Œæˆ"
}

# åˆå§‹åŒ–å‰ç«¯é¡¹ç›®
setup_frontend() {
    echo "ðŸŽ¨ è®¾ç½®å‰ç«¯é¡¹ç›®..."
    
    cd frontend/web
    
    # å®‰è£…ä¾èµ–
    echo "ðŸ“¦ å®‰è£…å‰ç«¯ä¾èµ–..."
    npm install
    
    # ç”Ÿæˆç±»åž‹å®šä¹‰
    echo "ðŸ”§ ç”Ÿæˆç±»åž‹å®šä¹‰..."
    npm run type-check
    
    cd ../..
    
    echo "âœ… å‰ç«¯é¡¹ç›®è®¾ç½®å®Œæˆ"
}

# å¯åŠ¨åŸºç¡€è®¾æ–½æœåŠ¡
start_infrastructure() {
    echo "ðŸ—ï¸  å¯åŠ¨åŸºç¡€è®¾æ–½æœåŠ¡..."
    
    cd deployment/docker-compose
    
    # å¯åŠ¨åŸºç¡€æœåŠ¡
    echo "ðŸš€ å¯åŠ¨æ•°æ®åº“å’Œç¼“å­˜æœåŠ¡..."
    docker-compose up -d mysql redis consul milvus etcd minio
    
    # ç­‰å¾…æœåŠ¡å¯åŠ¨
    echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨å®Œæˆ..."
    sleep 30
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    echo "ðŸ” æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
    docker-compose ps
    
    cd ../..
    
    echo "âœ… åŸºç¡€è®¾æ–½æœåŠ¡å¯åŠ¨å®Œæˆ"
}

# åˆ›å»ºé…ç½®æ–‡ä»¶
create_configs() {
    echo "ðŸ“ åˆ›å»ºé…ç½®æ–‡ä»¶..."
    
    # åˆ›å»ºé…ç½®ç›®å½•
    mkdir -p configs
    
    # åˆ›å»ºå¼€å‘çŽ¯å¢ƒé…ç½®
    cat > configs/config.yaml << EOF
server:
  http:
    port: 8080
    timeout: 30
  grpc:
    port: 9000
    timeout: 30

database:
  driver: mysql
  host: localhost
  port: 3306
  username: root
  password: resume123
  database: resume_optim
  max_open_conns: 100
  max_idle_conns: 10

redis:
  host: localhost
  port: 6379
  password: redis123
  db: 0

milvus:
  host: localhost
  port: 19530
  username: ""
  password: ""
  database: default
  collection: resume_knowledge

eino:
  model_provider: openai
  openai:
    api_key: \${OPENAI_API_KEY}
    base_url: https://api.openai.com/v1
    model: gpt-4
    temperature: 0.1
    max_tokens: 2000
  embeddings:
    provider: openai
    model: text-embedding-ada-002
    api_key: \${OPENAI_API_KEY}
  workflows:
    resume_parsing_timeout: 120
    analysis_timeout: 180
    knowledge_retrieval: 20
    max_concurrency: 5

log:
  level: debug
  encoding: console
  output_path: stdout

tracing:
  enabled: true
  service_name: resume-optim
  endpoint: http://localhost:14268/api/traces
EOF
    
    echo "âœ… é…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ"
}

# åˆ›å»ºçŽ¯å¢ƒå˜é‡æ–‡ä»¶
create_env_file() {
    echo "ðŸ”‘ åˆ›å»ºçŽ¯å¢ƒå˜é‡æ–‡ä»¶..."
    
    cat > .env << 'EOF'
# OpenAI APIå¯†é’¥ (å¿…é¡»è®¾ç½®)
OPENAI_API_KEY=your_openai_api_key_here

# æ•°æ®åº“é…ç½®
MYSQL_ROOT_PASSWORD=resume123
MYSQL_DATABASE=resume_optim
MYSQL_USER=resume_user
MYSQL_PASSWORD=resume123

# Redisé…ç½®
REDIS_PASSWORD=redis123

# MinIOé…ç½®
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin

# åº”ç”¨çŽ¯å¢ƒ
NODE_ENV=development
GO_ENV=development

# æœåŠ¡ç«¯å£é…ç½®
FRONTEND_PORT=3000
GATEWAY_PORT=8080
USER_SERVICE_PORT=8001
PARSER_SERVICE_PORT=8002
AI_SERVICE_PORT=8003
KNOWLEDGE_SERVICE_PORT=8004
FILE_SERVICE_PORT=8005
EOF
    
    echo "âš ï¸  è¯·ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½®ä½ çš„ OpenAI API Key"
    echo "âœ… çŽ¯å¢ƒå˜é‡æ–‡ä»¶åˆ›å»ºå®Œæˆ"
}

# åˆå§‹åŒ–æ•°æ®åº“
init_database() {
    echo "ðŸ—„ï¸  åˆå§‹åŒ–æ•°æ®åº“..."
    
    # ç­‰å¾…MySQLå¯åŠ¨
    echo "â³ ç­‰å¾…MySQLå¯åŠ¨..."
    sleep 20
    
    # åˆ›å»ºæ•°æ®åº“è¡¨
    echo "ðŸ“‹ åˆ›å»ºæ•°æ®åº“è¡¨..."
    cat > configs/mysql/init.sql << 'EOF'
-- åˆ›å»ºæ•°æ®åº“
CREATE DATABASE IF NOT EXISTS resume_optim CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
USE resume_optim;

-- ç”¨æˆ·è¡¨
CREATE TABLE IF NOT EXISTS users (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    full_name VARCHAR(100),
    avatar_url VARCHAR(255),
    status TINYINT DEFAULT 1,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    deleted_at TIMESTAMP NULL,
    INDEX idx_username (username),
    INDEX idx_email (email),
    INDEX idx_status (status)
);

-- ç®€åŽ†è¡¨
CREATE TABLE IF NOT EXISTS resumes (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id BIGINT NOT NULL,
    title VARCHAR(200) NOT NULL,
    file_path VARCHAR(500),
    file_type ENUM('pdf', 'markdown') NOT NULL,
    file_size BIGINT,
    parsed_content JSON,
    status TINYINT DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    deleted_at TIMESTAMP NULL,
    INDEX idx_user_id (user_id),
    INDEX idx_status (status),
    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
);

-- åˆ†æžç»“æžœè¡¨
CREATE TABLE IF NOT EXISTS analysis_results (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    resume_id BIGINT NOT NULL,
    overall_score DECIMAL(3,1),
    completeness_score DECIMAL(3,1),
    clarity_score DECIMAL(3,1),
    keyword_score DECIMAL(3,1),
    format_score DECIMAL(3,1),
    quantification_score DECIMAL(3,1),
    suggestions JSON,
    analysis_version VARCHAR(20),
    target_position VARCHAR(100),
    industry VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    deleted_at TIMESTAMP NULL,
    INDEX idx_resume_id (resume_id),
    FOREIGN KEY (resume_id) REFERENCES resumes(id) ON DELETE CASCADE
);

-- çŸ¥è¯†åº“è¡¨
CREATE TABLE IF NOT EXISTS knowledge_base (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    title VARCHAR(200) NOT NULL,
    content TEXT NOT NULL,
    category VARCHAR(50),
    tags JSON,
    file_path VARCHAR(500),
    vector_id VARCHAR(100),
    status TINYINT DEFAULT 1,
    created_by BIGINT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    deleted_at TIMESTAMP NULL,
    INDEX idx_category (category),
    INDEX idx_status (status),
    INDEX idx_created_by (created_by),
    FOREIGN KEY (created_by) REFERENCES users(id) ON DELETE SET NULL
);

-- çŸ¥è¯†å—è¡¨
CREATE TABLE IF NOT EXISTS knowledge_chunks (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    knowledge_id BIGINT NOT NULL,
    chunk_text TEXT NOT NULL,
    chunk_index INT NOT NULL,
    vector_id VARCHAR(100),
    token_count INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_knowledge_id (knowledge_id),
    FOREIGN KEY (knowledge_id) REFERENCES knowledge_base(id) ON DELETE CASCADE
);

-- æ’å…¥ç¤ºä¾‹æ•°æ®
INSERT IGNORE INTO users (username, email, password_hash, full_name) VALUES 
('admin', 'admin@example.com', '$2a$10$example_hash', 'ç³»ç»Ÿç®¡ç†å‘˜'),
('demo', 'demo@example.com', '$2a$10$example_hash', 'æ¼”ç¤ºç”¨æˆ·');

INSERT IGNORE INTO knowledge_base (title, content, category, tags, created_by) VALUES 
('è½¯ä»¶å·¥ç¨‹å¸ˆç®€åŽ†æ¨¡æ¿', 'è½¯ä»¶å·¥ç¨‹å¸ˆç®€åŽ†åº”è¯¥åŒ…å«ä»¥ä¸‹å…³é”®è¦ç´ ...', 'resume_tips', '["è½¯ä»¶å·¥ç¨‹å¸ˆ", "ç®€åŽ†æ¨¡æ¿"]', 1),
('æŠ€æœ¯æŠ€èƒ½æè¿°æœ€ä½³å®žè·µ', 'åœ¨ç®€åŽ†ä¸­æè¿°æŠ€æœ¯æŠ€èƒ½æ—¶ï¼Œåº”è¯¥æ³¨æ„ä»¥ä¸‹å‡ ç‚¹...', 'best_practice', '["æŠ€æœ¯æŠ€èƒ½", "æœ€ä½³å®žè·µ"]', 1);
EOF
    
    echo "âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ"
}

# æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
show_startup_info() {
    echo ""
    echo "ðŸŽ‰ å¼€å‘çŽ¯å¢ƒè®¾ç½®å®Œæˆï¼"
    echo ""
    echo "ðŸ“ æœåŠ¡åœ°å€ï¼š"
    echo "  - å‰ç«¯åº”ç”¨: http://localhost:3000"
    echo "  - APIç½‘å…³: http://localhost:8080"
    echo "  - Consul: http://localhost:8500"
    echo "  - MinIO: http://localhost:9001"
    echo "  - Grafana: http://localhost:3001 (admin/admin123)"
    echo "  - Jaeger: http://localhost:16686"
    echo ""
    echo "ðŸš€ å¯åŠ¨æœåŠ¡ï¼š"
    echo "  - å¯åŠ¨å‰ç«¯: cd frontend/web && npm run dev"
    echo "  - å¯åŠ¨åŽç«¯æœåŠ¡: make dev"
    echo "  - æŸ¥çœ‹æ—¥å¿—: docker-compose -f deployment/docker-compose/docker-compose.yml logs -f"
    echo ""
    echo "âš ï¸  æ³¨æ„äº‹é¡¹ï¼š"
    echo "  1. è¯·ç¡®ä¿å·²è®¾ç½® OPENAI_API_KEY çŽ¯å¢ƒå˜é‡"
    echo "  2. é¦–æ¬¡å¯åŠ¨å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ä¸‹è½½é•œåƒ"
    echo "  3. å¦‚é‡é—®é¢˜è¯·æŸ¥çœ‹æ—¥å¿—æˆ–é‡å¯æœåŠ¡"
    echo ""
}

# ä¸»å‡½æ•°
main() {
    check_prerequisites
    create_configs
    create_env_file
    setup_backend
    setup_frontend
    start_infrastructure
    init_database
    show_startup_info
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
